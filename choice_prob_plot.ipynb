{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barendregt/programs/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:17: FutureWarning: The pandas.rpy module is deprecated and will be removed in a future version. We refer to external packages like rpy2. \n",
      "See here for a guide on how to port your code to rpy2: http://pandas.pydata.org/pandas-docs/stable/r_interface.html\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.formula.api import ols\n",
    "# from statsmodels.stats.anova import anova_lm\n",
    "# from numpy import *\n",
    "# import scipy as sp\n",
    "# from pandas import *\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as ro\n",
    "import pandas.rpy.common as com\n",
    "\n",
    "from math import *\n",
    "import os,glob,sys,platform\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "from IPython import embed\n",
    "\n",
    "from BehaviorAnalyzer import BehaviorAnalyzer\n",
    "from PupilAnalyzer import PupilAnalyzer\n",
    "from Plotter import Plotter\n",
    "\n",
    "\n",
    "from analysis_parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitcdf(x,s):\n",
    "    return sp.stats.norm.cdf(x,0,s)\n",
    "\n",
    "def bootstrap_data(samples, new_size=1000):\n",
    "    \n",
    "    return resample(samples, replace=True, n_samples=new_size)\n",
    "    \n",
    "\n",
    "def estimate_auc(X,Y, niter = 1000, verbose = False):\n",
    "\n",
    "    y = label_binarize(Y, classes=[0, 1])\n",
    "    x = X[:,np.newaxis]\n",
    "\n",
    "    # shuffle and split training and test sets\n",
    "    roc_auc = np.zeros((niter,1))\n",
    "    for i in range(niter):\n",
    "        \n",
    "        if verbose and ((i>0) and (i%10==0)):\n",
    "            print('iteration: %i'%i)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.3)\n",
    "\n",
    "        # Learn to predict each class against the other\n",
    "        classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "        y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "        \n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "        roc_auc[i] = auc(fpr, tpr)\n",
    "\n",
    "    return roc_auc.mean(), roc_auc\n",
    "\n",
    "def estimate_auc_xgb(X,Y,param,niter=1000, verbose = False):\n",
    "    \n",
    "    num_round = 2\n",
    "    \n",
    "    y = label_binarize(Y, classes=[0, 1])\n",
    "    x = X[:,np.newaxis]\n",
    "\n",
    "    # shuffle and split training and test sets\n",
    "    roc_auc = np.zeros((niter,1))\n",
    "    for i in range(niter):\n",
    "        \n",
    "        if verbose and ((i>0) and (i%10==0)):\n",
    "            print('iteration: %i'%i)\n",
    "                \n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.5)\n",
    "\n",
    "        # Learn to predict each class against the other\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dtest  = xgb.DMatrix(X_test, label=y_test)\n",
    "        \n",
    "        watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "        bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "\n",
    "        y_score = bst.predict(dtest)\n",
    "        \n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "        roc_auc[i] = auc(fpr, tpr)\n",
    "\n",
    "    return roc_auc.mean(), roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "\n",
    "VERBOSITY = True\n",
    "\n",
    "pl = Plotter(figure_folder = figfolder, linestylemap = linestylemap)\n",
    "\n",
    "condition_keymap = { 0: 'PP',  1: 'PP',\n",
    "10: 'PU', 20: 'PU',\n",
    "30: 'UP', 40: 'UP',\n",
    "50: 'UP', 60: 'UP'}\n",
    "\n",
    "inverse_keymap = {'PP': [0,1],\n",
    "  'UU': [30,40],\n",
    "  'PU': [10,20,50,60]}\n",
    "#   'UP': [50,60]}\n",
    "\n",
    "choice_prob = {'UP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*(deconv_sample_frequency))),dtype=float),\n",
    "   'PU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*(deconv_sample_frequency))),dtype=float)} \n",
    "\n",
    "all_pupil_correct = {'UP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*(deconv_sample_frequency))),dtype=float),\n",
    " 'PU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*(deconv_sample_frequency))),dtype=float)}\n",
    "\n",
    "all_pupil_incorrect = {'UP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*(deconv_sample_frequency))),dtype=float),\n",
    "   'PU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*(deconv_sample_frequency))),dtype=float)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-46c1051cb761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpupil_HR1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mt0_HR1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpupil_HR1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mt0_FA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpupil_FA1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mt0_HR2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpupil_HR2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mt0_FA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpupil_FA2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-56f5f211c9cf>\u001b[0m in \u001b[0;36mbootstrap_data\u001b[0;34m(samples, new_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbootstrap_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/barendregt/programs/anaconda/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_n_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randint (numpy/random/mtrand/mtrand.c:15485)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "for subname in sublist:\n",
    "\n",
    "\t# Organize filenames\n",
    "\trawfolder = os.path.join(raw_data_folder,subname)\n",
    "\tsharedfolder = os.path.join(shared_data_folder,subname)\n",
    "\tcsvfilename = glob.glob(rawfolder + '/*.csv')#[-1]\n",
    "\th5filename = os.path.join(sharedfolder,subname+'.h5')\n",
    "\n",
    "\t# Initialize PA object\n",
    "\tpa = PupilAnalyzer(subname, h5filename, rawfolder, reference_phase = 7, signal_downsample_factor = down_fs, signal_sample_frequency = signal_sample_frequency, deconv_sample_frequency = deconv_sample_frequency, deconvolution_interval = stimulus_deconvolution_interval, verbosity = 0)\n",
    "\n",
    "\n",
    "\t# Combine signals based on condition\n",
    "\n",
    "\tsub_signals = {'HR1': {'PP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'UP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'PU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'UU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float)},\n",
    "\t'FA1': {'PP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'UP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'PU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'UU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float)},\n",
    "\t'HR2': {'PP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'UP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'PU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'UU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float)},\n",
    "\t'FA2': {'PP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'UP': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'PU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float),\n",
    "\t'UU': np.empty((0,int((stimulus_deconvolution_interval[1] - stimulus_deconvolution_interval[0])*signal_sample_frequency)),dtype=float)},\n",
    "\t} \n",
    "\n",
    "\t# Get trial-based, event-related, baseline-corrected signals centered on stimulus onset\n",
    "\tpa.signal_per_trial(only_FA = False, only_Hit = True, sdt_dir = 1, reference_phase = 7, with_rt = False, baseline_type = 'relative', baseline_period = [-.5, 0.0], force_rebuild=False, down_sample = False, return_rt = False)\n",
    "\n",
    "\tfor (key,signals) in pa.trial_signals.items():\n",
    "\t\tif len(signals)>0:\n",
    "\t\t\tsub_signals['HR1'][condition_keymap[key]] = np.append(sub_signals['HR1'][condition_keymap[key]], signals, axis=0)\n",
    "\n",
    "\t# Get trial-based, event-related, baseline-corrected signals centered on stimulus onset\n",
    "\tpa.signal_per_trial(only_FA = True, only_Hit = False, sdt_dir = 1, reference_phase = 7, with_rt = False, baseline_type = 'relative', baseline_period = [-.5, 0.0], force_rebuild=False, down_sample = False, return_rt = False)\n",
    "\n",
    "\tfor (key,signals) in pa.trial_signals.items():\n",
    "\t\tif len(signals)>0:\n",
    "\t\t\tsub_signals['FA1'][condition_keymap[key]] = np.append(sub_signals['FA1'][condition_keymap[key]], signals, axis=0)\n",
    "\n",
    "\t# Get trial-based, event-related, baseline-corrected signals centered on stimulus onset\n",
    "\tpa.signal_per_trial(only_FA = False, only_Hit = True, sdt_dir = -1, reference_phase = 7, with_rt = False, baseline_type = 'relative', baseline_period = [-.5, 0.0], force_rebuild=False, down_sample = False, return_rt = False)\n",
    "\n",
    "\tfor (key,signals) in pa.trial_signals.items():\n",
    "\t\tif len(signals)>0:\n",
    "\t\t\tsub_signals['HR2'][condition_keymap[key]] = np.append(sub_signals['HR2'][condition_keymap[key]], signals, axis=0)\n",
    "\n",
    "\t# Get trial-based, event-related, baseline-corrected signals centered on stimulus onset\n",
    "\tpa.signal_per_trial(only_FA = True, only_Hit = False, sdt_dir = -1, reference_phase = 7, with_rt = False, baseline_type = 'relative', baseline_period = [-.5, 0.0], force_rebuild=False, down_sample = False, return_rt = False)\n",
    "\n",
    "\tfor (key,signals) in pa.trial_signals.items():\n",
    "\t\tif len(signals)>0:\n",
    "\t\t\tsub_signals['FA2'][condition_keymap[key]] = np.append(sub_signals['FA2'][condition_keymap[key]], signals, axis=0)\n",
    "\n",
    "\tbase_HR1 = sp.signal.decimate(sub_signals['HR1']['PP'],down_fs,1)\n",
    "\tbase_FA1 = sp.signal.decimate(sub_signals['FA1']['PP'],down_fs,1)\n",
    "\tbase_HR2 = sp.signal.decimate(sub_signals['HR2']['PP'],down_fs,1)\n",
    "\tbase_FA2 = sp.signal.decimate(sub_signals['FA2']['PP'],down_fs,1)\n",
    "\n",
    "\t#     pupil_correct = {'UP': sp.signal.decimate(sub_signals['correct']['UP'],down_fs,1),\n",
    "\t#                          'PU': sp.signal.decimate(sub_signals['correct']['PU'],down_fs,1)}\n",
    "\n",
    "\t#     pupil_incorrect = {'UP': sp.signal.decimate(sub_signals['incorrect']['UP'],down_fs,1),\n",
    "\t#                        'PU': sp.signal.decimate(sub_signals['incorrect']['PU'],down_fs,1)}\n",
    "\n",
    "\n",
    "\tpupil_HR1 = {'UP': sp.signal.decimate(sub_signals['HR1']['UP'],down_fs,1) - base_HR1.mean(axis=0),\n",
    "\t'PU': sp.signal.decimate(sub_signals['HR1']['PU'],down_fs,1) - base_HR1.mean(axis=0)}\n",
    "\n",
    "\tpupil_HR2 = {'UP': sp.signal.decimate(sub_signals['HR2']['UP'],down_fs,1) - base_HR2.mean(axis=0),\n",
    "\t'PU': sp.signal.decimate(sub_signals['HR2']['PU'],down_fs,1) - base_HR2.mean(axis=0)}    \n",
    "\n",
    "\tpupil_FA1 = {'UP': sp.signal.decimate(sub_signals['FA1']['UP'],down_fs,1) - base_FA1.mean(axis=0),\n",
    "\t'PU': sp.signal.decimate(sub_signals['FA1']['PU'],down_fs,1) - base_FA1.mean(axis=0)}\n",
    "\n",
    "\tpupil_FA2 = {'UP': sp.signal.decimate(sub_signals['FA2']['UP'],down_fs,1) - base_FA2.mean(axis=0),\n",
    "\t'PU': sp.signal.decimate(sub_signals['FA2']['PU'],down_fs,1) - base_FA2.mean(axis=0)}    \n",
    "\n",
    "\n",
    "\tsub_choice_prob = {'UP': np.zeros((pupil_HR1['UP'].shape[1])),'PU': np.zeros((pupil_HR1['PU'].shape[1]))}\n",
    "\n",
    "\tfor key in list(choice_prob.keys()):\n",
    "\t\tfor t in range(0,pupil_HR1[key].shape[1]):\n",
    "\t\t\tif (len(pupil_HR1[key])>0) & (len(pupil_FA1[key])>0):\n",
    "\t\t\t\tt0_HR1 = bootstrap_data(pupil_HR1[key][:,t], new_size=100)\n",
    "\t\t\t\tt0_FA1 = bootstrap_data(pupil_FA1[key][:,t], new_size=100)\n",
    "\t\t\t\tprob1,_ = estimate_auc(np.hstack([t0_HR1, t0_FA1]), np.hstack([np.ones((t0_HR1.shape[0],)), np.zeros((t0_FA1.shape[0],))]), niter=10)\t\t\t\t\n",
    "\t\t\telse:\t\t\t\t\n",
    "\t\t\t\tprob1 = 0.5\n",
    "\n",
    "\t\t\tif (len(pupil_HR2[key])>0) & (len(pupil_FA2[key])>0):\n",
    "         \n",
    "\t\t\t\tt0_HR2 = bootstrap_data(pupil_HR2[key][:,t], new_size=100)\n",
    "\t\t\t\tt0_FA2 = bootstrap_data(pupil_FA2[key][:,t], new_size=100)\n",
    "\n",
    "\t\t\t\tprob2,_ = estimate_auc(np.hstack([t0_HR2, t0_FA2]), np.hstack([np.ones((t0_HR2.shape[0],)), np.zeros((t0_FA2.shape[0],))]), niter=10)\n",
    "\t\t\t\t\n",
    "\t\t\telse:   \n",
    "\t\t\t\tprob2 = 0.5\n",
    "\t\t\tsub_choice_prob[key][t] = (prob1+prob2)/2\n",
    "\n",
    "\t\tchoice_prob[key] = np.append(choice_prob[key], sub_choice_prob[key][np.newaxis,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving the results should be a good idea...\n",
    "\n",
    "fname = 'all_pupil_data'\n",
    "\n",
    "with open(fname+'_correct','wb') as f:\n",
    "    pickle.dump(all_pupil_correct,f)\n",
    "    f.close()    \n",
    "    \n",
    "with open(fname+'_incorrect','wb') as f:\n",
    "    pickle.dump(all_pupil_incorrect,f)    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('bla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(subname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_per_t = []\n",
    "\n",
    "for t in range(all_pupil_correct['PU'].shape[1]):\n",
    "    data = np.hstack([all_pupil_correct['PU'][:,t], all_pupil_incorrect['PU'][:,t]])\n",
    "    labels = np.hstack([np.ones((1,all_pupil_correct['PU'].shape[0])), np.zeros((1,all_pupil_incorrect['PU'].shape[0]))]).T\n",
    "    \n",
    "    if VERBOSITY:\n",
    "        print('time point: %i'%t)\n",
    "    \n",
    "    auc_per_t.append(estimate_auc(data,labels,niter=10, verbose=VERBOSITY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eta\": 1.0,\n",
    "    \"tree_method\": 'exact',\n",
    "    \"max_depth\": 2,\n",
    "    \"silent\": 1,\n",
    "}\n",
    "\n",
    "auc_per_t_xgb = []\n",
    "\n",
    "for t in range(all_pupil_correct['PU'].shape[1]):\n",
    "    data = np.hstack([all_pupil_correct['PU'][:,t], all_pupil_incorrect['PU'][:,t]])\n",
    "    labels = np.hstack([np.ones((1,all_pupil_correct['PU'].shape[0])), np.zeros((1,all_pupil_incorrect['PU'].shape[0]))]).T\n",
    "    \n",
    "    if VERBOSITY:\n",
    "        print('time point: %i'%t)    \n",
    "    \n",
    "    auc_per_t_xgb.append(estimate_auc_xgb(data,labels,params,niter=10, verbose=VERBOSITY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "choice_prob = {'xgb': np.array([mval for mval,_ in auc_per_t_xgb])}\n",
    "\n",
    "pl.linestylemap = None\n",
    "\n",
    "# PLOT STUFF\n",
    "\n",
    "smooth_factor = 10# deconv_sample_frequency\n",
    "\n",
    "# embed()\n",
    "\n",
    "pl.open_figure(force=1)\n",
    "\n",
    "# pl.subplot(1,2,1)\n",
    "\n",
    "pl.hline(0.5)\n",
    "#pl.event_related_pupil_average(choice_prob,conditions=['UP'],signal_labels={'UP':'TaskRel/dt'},x_lim=[80,200],xticks=[100,110,120,130,140,150,200,250],xticklabels=[0,.1,.2,.3,.4,.5,1,1.5], compute_mean=True,compute_sd=True,show_legend=True, ylabel='Choice probability', y_lim=[0.4,0.6], with_stats=True, stats_ttest_ref=0.5, sig_marker_ypos = 0.41, after_smooth=True, after_smooth_factor = 50)\n",
    "pl.event_related_pupil_average(choice_prob,conditions=['xgb'],signal_labels={'svm':'svm','xgb':'xgb'},\n",
    "                              x_lim=[0.8*50,4.5*50],xticks=np.arange(0.5*50,5.0*50,0.5*50),xticklabels=np.arange(-0.5,4.5,0.5),\n",
    "                              ylabel='Choice probability', y_lim=[0.4,0.6], show_legend=True,\n",
    "                              with_stats=False, compute_mean=False, compute_sd =False, mark_first_sig = False,\n",
    "                              smooth_signal=False, smooth_factor=smooth_factor,\n",
    "                              after_smooth=True,after_smooth_window=11)\n",
    "# pl.vline(107, label='70ms', linestyle='solid')\n",
    "pl.show()\n",
    "# pl.save_figure(filename='choice_probs_smooth.pdf', sub_folder='over_subs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(choice_prob['svm'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PLOT STUFF\n",
    "\n",
    "smooth_factor = 10# deconv_sample_frequency\n",
    "\n",
    "# embed()\n",
    "\n",
    "pl.open_figure(force=1)\n",
    "\n",
    "# pl.subplot(1,2,1)\n",
    "\n",
    "pl.hline(0.5)\n",
    "#pl.event_related_pupil_average(choice_prob,conditions=['UP'],signal_labels={'UP':'TaskRel/dt'},x_lim=[80,200],xticks=[100,110,120,130,140,150,200,250],xticklabels=[0,.1,.2,.3,.4,.5,1,1.5], compute_mean=True,compute_sd=True,show_legend=True, ylabel='Choice probability', y_lim=[0.4,0.6], with_stats=True, stats_ttest_ref=0.5, sig_marker_ypos = 0.41, after_smooth=True, after_smooth_factor = 50)\n",
    "pl.event_related_pupil_average(choice_prob,conditions=['UP','PU'],signal_labels=keymap_to_words,\n",
    "                              x_lim=[0*50,4.5*50],xticks=np.arange(0.5*50,5.0*50,0.5*50),xticklabels=np.arange(-0.5,4.5,0.5),\n",
    "                              ylabel='Choice probability', y_lim=[0.4,0.6], \n",
    "                              with_stats=True, stats_ttest_ref=0.5, stats_ttest_p = 0.01, sig_marker_ypos = 0.41, compute_mean=True, compute_sd =True, mark_first_sig = False,\n",
    "                              smooth_signal=False, smooth_factor=smooth_factor,\n",
    "                              after_smooth=True,after_smooth_window=11)\n",
    "# pl.vline(107, label='70ms', linestyle='solid')\n",
    "pl.show()\n",
    "# pl.save_figure(filename='choice_probs_smooth.pdf', sub_folder='over_subs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
